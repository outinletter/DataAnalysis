{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "참고, 코딩, SMOTE, 부족한 데이터셋.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNh//zBI/BjmSV69M9c8Y/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/outinletter/DataAnalysis/blob/main/%EC%B0%B8%EA%B3%A0%2C_%EC%BD%94%EB%94%A9%2C_SMOTE%2C_%EB%B6%80%EC%A1%B1%ED%95%9C_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5hixWwrXtxE"
      },
      "source": [
        "# 부족한 데이터 불규형\n",
        "\n",
        "- 데이터 분석 시 데이터의 불균형의 문제 (예, 부도 예측시 전체 기업의 3% 내외)\n",
        "- 비대칭 데이터셋에서는 정확도가 높아도 재현율이 현저히 작아짐\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9b_8Fa0YH7y"
      },
      "source": [
        "# 데이터 불균형 처리 방법\n",
        "- 언더샘플링\n",
        "    - 무작위로 정상 데이터를 일부만 선택(EasyEnsemble, BalanceCascade)\n",
        "    - 언더샘플링의 경우 데이터의 소실이 매우 크고, 중요한 정상데이터를 잃게되는 단점\n",
        "- 오버샘플링\n",
        "    - 무작위로 소수 데이터를 복제\n",
        "    - 정보 손실은 없으나, 복제된 관측치로 오버피팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L2FXlxkY37U"
      },
      "source": [
        "# SMOTE(synthetic minority oversampling technique)\n",
        "- 다수 클래스를 샘플링하고 기존 소수 샘플을 보간하여 새로운 소수 인스턴스를 합성\n",
        "- 소수데이터들 사이를 보간하여 작동\n",
        "- 새로운 사례의 데이터 예측엔 취약"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAng-61wZ0FD"
      },
      "source": [
        "# 데이터 스케일링\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit_transform(X_train)\n",
        "X_train = scaler.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0-CnPJdZqMI"
      },
      "source": [
        "# 데이터 복제\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 모델 설정\n",
        "sm = SMOTE(ratio='auto', kind='regular')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL5nS6IwaCDG"
      },
      "source": [
        "# train데이터를 넣어 복제\n",
        "X_resampled, y_resampled = sm.fit_sample(X_train,list(y_train))\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_resampled.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(X_resampled.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_resampled==1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_resampled==0)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLlZAqPnaCAQ"
      },
      "source": [
        "# 정상데이터수를 기준으로 50% : 50%로 소수데이터가 합성\n",
        "X_resampled.shape, y_resampled.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmRvxDpaaf4"
      },
      "source": [
        "# Borderline-SMOTE\n",
        "## A New Over-Sampling Method in Imbalanced Data Sets Learning\n",
        "- 연예인 얼굴처럼 데이터가 많이 존재하는 class를 majority class라고 하고, 일반인 얼굴처럼 적게 존재하는 class를 minority class\n",
        "- 기존의 SMOTE 알고리즘이 단순히 minority class에서 랜덤하게 샘플링 했다면, Borderline-SMOTE는 다른 class와의 경계(borderline)에 있는 샘플들을 늘림으로써 분류하기 더 어려운 부분에 집중"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prMC_uWKathc"
      },
      "source": [
        "## 샘플링 순서\n",
        "1. minority class에 속한 모든 example에 대하여 minor, major 구분 없이 nearest neighbor를 추출\n",
        "2. 뽑아낸 nearest neighbor 중 절반 이상이 majority class이며 이 example을 DANGER 라고 하는데, 이는 곧 borderline에 있는 분류기가 어려워하는 example의 set을 의미\n",
        "3. 경계에 있는 샘플들, 즉 DANGER set에 대하여 nearest neighbor들을 다시 뽑는다. 이 때는 minority class에서만 뽑아낸다.\n",
        "4. 인위적으로 생성한 데이터, synthetic example을 만드는데, 위와 같이 기존의 minority example (p'i) 에 뽑아낸 nearest neighbor 과의 차이(dif j)를 랜덤 비율(r j)로 더한 값을 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytkc-S1_ckZk"
      },
      "source": [
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "\n",
        "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9], \n",
        "                           n_informative=3, n_redundant=1, flip_y=0, n_features=20, \n",
        "                           n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
        "print('Original dataset shape %s' % Counter(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITpKLBvgcrmV"
      },
      "source": [
        "Original dataset shape Counter({1: 900, 0: 100})\n",
        "sm = BorderlineSMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))\n",
        "Resampled dataset shape Counter({0: 900, 1: 900})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8bJ5va9cu_L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xt2TF6Vcvtd"
      },
      "source": [
        "## Imbalanced small dataset으로 변형"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teRT9APZX5eR"
      },
      "source": [
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gccuJlReZMNM"
      },
      "source": [
        "EPOCHS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sVkoUhdZMLI"
      },
      "source": [
        "# 모델\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.flatten = tf.keras.layers.Flatten() \n",
        "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU9Aug8WZMI7"
      },
      "source": [
        "# 불규형 데이터셋\n",
        "cifar10 = tf.keras.datasets.cifar10 # 32x32x3\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# TODO: 학습 데이터를 Imbalanced small dataset으로 변형하기\n",
        "x_train_small = list()\n",
        "y_train_small = list()\n",
        "for x, y in zip(x_train, y_train):\n",
        "    if (y == 0 and random.randint(0, 100) < 10) or y == 1:\n",
        "        x_train_small.append(x[:])\n",
        "        y_train_small.append(y)\n",
        "\n",
        "x_test_small = list()\n",
        "y_test_small = list()\n",
        "for x, y in zip(x_test, y_test):\n",
        "    if y == 0 or y == 1:\n",
        "        x_test_small.append(x[:])\n",
        "        y_test_small.append(y)\n",
        "\n",
        "x_train = np.stack(x_train_small, axis=0)\n",
        "y_train = np.stack(y_train_small, axis=0)\n",
        "\n",
        "x_test = np.stack(x_test_small, axis=0)\n",
        "y_test = np.stack(y_test_small, axis=0)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(2048)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt8MMBUXZMGo"
      },
      "source": [
        "# Keras API 모델 학습 (불균형한 데이터셋)\n",
        "model = MyModel()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy',\n",
        "                       tf.keras.metrics.Precision(name='precision'),\n",
        "                       tf.keras.metrics.Recall(name='recall')])\n",
        "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQmOfBBZMEB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}